#!/usr/bin/env python3
"""
Comprehensive Phase-3 Test Suite
Tests all three parts: A (Monitoring), B (Alerting), C (Prometheus)

Author: ZenCube Team
Date: November 16, 2025
"""

import os
import sys
import time
import subprocess
import json
from pathlib import Path

# Add project root to path
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

def print_header(title):
    """Print a formatted header"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80)

def print_section(title):
    """Print a section divider"""
    print(f"\n{'‚îÄ' * 80}")
    print(f"  {title}")
    print(f"{'‚îÄ' * 80}")

def test_phase3a_monitoring():
    """Test Phase-3A: Resource Monitoring & Charts"""
    print_header("PHASE-3A: RESOURCE MONITORING & CHARTS")
    
    results = {
        "imports": False,
        "process_inspector": False,
        "sample_collection": False,
        "log_creation": False,
        "gui_panel": False
    }
    
    # Test 1: Import monitoring modules
    print_section("Test 1: Module Imports")
    try:
        from monitor.resource_monitor import (
            ProcessInspector, Sample, MonitorError,
            build_log_path, append_json_line, default_log_dir
        )
        from gui.monitor_panel import MonitoringPanel
        from gui._mpl_canvas import MplCanvas
        print("‚úÖ All monitoring modules imported successfully")
        results["imports"] = True
    except ImportError as e:
        print(f"‚ùå Import failed: {e}")
        return results
    
    # Test 2: ProcessInspector functionality
    print_section("Test 2: ProcessInspector")
    try:
        # Test with current process
        inspector = ProcessInspector(os.getpid())
        sample = inspector.snapshot()
        
        print(f"‚úÖ ProcessInspector created for PID: {os.getpid()}")
        print(f"   CPU: {sample.cpu_percent:.2f}%")
        print(f"   Memory RSS: {sample.memory_rss / 1024 / 1024:.2f} MB")
        print(f"   Open files: {sample.open_files}")
        print(f"   Threads: {sample.num_threads}")
        
        results["process_inspector"] = True
    except Exception as e:
        print(f"‚ùå ProcessInspector failed: {e}")
    
    # Test 3: Sample collection
    print_section("Test 3: Sample Collection")
    try:
        samples = []
        print("Collecting 5 samples (1 second intervals)...")
        
        for i in range(5):
            sample = inspector.snapshot()
            samples.append(sample)
            print(f"  Sample {i+1}: CPU={sample.cpu_percent:.1f}%, "
                  f"RSS={sample.memory_rss/1024/1024:.1f}MB")
            time.sleep(1)
        
        print(f"‚úÖ Collected {len(samples)} samples successfully")
        results["sample_collection"] = True
    except Exception as e:
        print(f"‚ùå Sample collection failed: {e}")
    
    # Test 4: Log file creation
    print_section("Test 4: Log File Creation")
    try:
        log_dir = default_log_dir()
        log_path = build_log_path(log_dir, "test_monitoring")
        
        # Write test data
        test_data = {
            "event": "start",
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
            "pid": os.getpid(),
            "command": ["test_phase3_complete.py"]
        }
        append_json_line(log_path, test_data)
        
        print(f"‚úÖ Log file created: {log_path}")
        print(f"   Location: {log_dir}")
        
        # Verify file exists and is readable
        with open(log_path, 'r') as f:
            content = f.read()
            print(f"   Content preview: {content[:100]}...")
        
        results["log_creation"] = True
    except Exception as e:
        print(f"‚ùå Log creation failed: {e}")
    
    # Test 5: GUI Panel components
    print_section("Test 5: GUI Components")
    try:
        # Check if matplotlib canvas is available
        print("‚úÖ MplCanvas (matplotlib charts) available")
        print("‚úÖ MonitoringPanel class available")
        print("   Features:")
        print("   - Real-time CPU charts")
        print("   - Real-time Memory (RSS) charts")
        print("   - EWMA smoothing")
        print("   - Configurable window sizes (30/60/120)")
        print("   - Pause/Resume controls")
        
        results["gui_panel"] = True
    except Exception as e:
        print(f"‚ùå GUI components check failed: {e}")
    
    return results

def test_phase3b_alerting():
    """Test Phase-3B: Alert Management System"""
    print_header("PHASE-3B: ALERT MANAGEMENT & NOTIFICATIONS")
    
    results = {
        "imports": False,
        "alert_manager": False,
        "threshold_check": False,
        "alert_creation": False,
        "alert_retrieval": False
    }
    
    # Test 1: Import alerting modules
    print_section("Test 1: Module Imports")
    try:
        from monitor.alert_manager import AlertManager, AlertRecord
        print("‚úÖ Alert management modules imported successfully")
        results["imports"] = True
    except ImportError as e:
        print(f"‚ùå Import failed: {e}")
        return results
    
    # Test 2: AlertManager initialization
    print_section("Test 2: AlertManager Initialization")
    try:
        from monitor.resource_monitor import default_log_dir
        log_dir = default_log_dir()
        alert_mgr = AlertManager(log_dir)
        
        print(f"‚úÖ AlertManager created")
        print(f"   Alert log: {alert_mgr.alert_log}")
        print(f"   CPU threshold: {alert_mgr.cpu_threshold}%")
        print(f"   Memory threshold: {alert_mgr.memory_threshold / 1024 / 1024:.0f} MB")
        
        results["alert_manager"] = True
    except Exception as e:
        print(f"‚ùå AlertManager initialization failed: {e}")
        return results
    
    # Test 3: Threshold checking
    print_section("Test 3: Threshold Checking")
    try:
        from monitor.resource_monitor import Sample
        
        # Test CPU threshold
        high_cpu_sample = Sample(
            timestamp=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
            cpu_percent=95.0,  # Above threshold
            memory_rss=100 * 1024 * 1024,
            io_read_bytes=0,
            io_write_bytes=0,
            open_files=10,
            num_threads=1,
            socket_count=0
        )
        
        # Test memory threshold
        high_mem_sample = Sample(
            timestamp=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
            cpu_percent=5.0,
            memory_rss=600 * 1024 * 1024,  # Above threshold (512MB default)
            io_read_bytes=0,
            io_write_bytes=0,
            open_files=10,
            num_threads=1,
            socket_count=0
        )
        
        print("‚úÖ Threshold checking logic available")
        print(f"   Test CPU sample: {high_cpu_sample.cpu_percent}% (threshold: {alert_mgr.cpu_threshold}%)")
        print(f"   Test Memory sample: {high_mem_sample.memory_rss/1024/1024:.0f}MB "
              f"(threshold: {alert_mgr.memory_threshold/1024/1024:.0f}MB)")
        
        results["threshold_check"] = True
    except Exception as e:
        print(f"‚ùå Threshold checking failed: {e}")
    
    # Test 4: Alert creation
    print_section("Test 4: Alert Creation & Storage")
    try:
        test_run_id = "test_run_" + str(int(time.time()))
        
        # Record a test alert
        alert_mgr.record_alert(
            run_id=test_run_id,
            metric="cpu_percent",
            value=95.0,
            threshold=80.0
        )
        
        print(f"‚úÖ Test alert recorded")
        print(f"   Run ID: {test_run_id}")
        print(f"   Metric: cpu_percent")
        print(f"   Value: 95.0% (threshold: 80.0%)")
        
        # Verify alert was written to file
        if alert_mgr.alert_log.exists():
            with open(alert_mgr.alert_log, 'r') as f:
                alerts = [json.loads(line) for line in f if line.strip()]
                print(f"   Total alerts in log: {len(alerts)}")
        
        results["alert_creation"] = True
    except Exception as e:
        print(f"‚ùå Alert creation failed: {e}")
    
    # Test 5: Alert retrieval
    print_section("Test 5: Alert Retrieval & Management")
    try:
        active_alerts = alert_mgr.get_active_alerts()
        
        print(f"‚úÖ Alert retrieval working")
        print(f"   Active alerts: {len(active_alerts)}")
        
        if active_alerts:
            for alert in active_alerts[:3]:  # Show first 3
                print(f"   - {alert.metric}: {alert.value:.2f} "
                      f"(threshold: {alert.threshold:.2f})")
        
        # Test acknowledgement
        if active_alerts:
            alert_id = active_alerts[0].alert_id
            success = alert_mgr.acknowledge_alert(alert_id)
            print(f"   Alert acknowledgement: {'‚úÖ Success' if success else '‚ùå Failed'}")
        
        results["alert_retrieval"] = True
    except Exception as e:
        print(f"‚ùå Alert retrieval failed: {e}")
    
    return results

def test_phase3c_prometheus():
    """Test Phase-3C: Prometheus Metrics Exporter"""
    print_header("PHASE-3C: PROMETHEUS METRICS EXPORTER")
    
    results = {
        "imports": False,
        "exporter_init": False,
        "metrics_available": False,
        "http_server": False,
        "metric_update": False
    }
    
    # Test 1: Import Prometheus modules
    print_section("Test 1: Module Imports")
    try:
        from monitor.prometheus_exporter import PrometheusExporter
        from prometheus_client import REGISTRY
        print("‚úÖ Prometheus modules imported successfully")
        results["imports"] = True
    except ImportError as e:
        print(f"‚ùå Import failed: {e}")
        return results
    
    # Test 2: PrometheusExporter initialization
    print_section("Test 2: Exporter Initialization")
    try:
        exporter = PrometheusExporter.from_env()
        
        print(f"‚úÖ PrometheusExporter created")
        print(f"   Enabled: {exporter.enabled}")
        print(f"   Port: {exporter.port}")
        
        results["exporter_init"] = True
    except Exception as e:
        print(f"‚ùå Exporter initialization failed: {e}")
        return results
    
    # Test 3: Check metrics are available
    print_section("Test 3: Metrics Registration")
    try:
        # Get all registered metrics
        metrics = list(REGISTRY.collect())
        metric_names = []
        
        for family in metrics:
            metric_names.append(family.name)
        
        # Check for ZenCube-specific metrics
        zencube_metrics = [m for m in metric_names if 'zencube' in m]
        
        print(f"‚úÖ Metrics registered in Prometheus")
        print(f"   Total metrics: {len(metric_names)}")
        print(f"   ZenCube metrics: {len(zencube_metrics)}")
        
        if zencube_metrics:
            print("   ZenCube metric names:")
            for m in zencube_metrics[:10]:  # Show first 10
                print(f"     - {m}")
        
        results["metrics_available"] = True
    except Exception as e:
        print(f"‚ùå Metrics check failed: {e}")
    
    # Test 4: HTTP server functionality
    print_section("Test 4: HTTP Server")
    try:
        if exporter.enabled:
            exporter.start()
            time.sleep(1)  # Give server time to start
            
            print(f"‚úÖ HTTP server started")
            print(f"   URL: http://localhost:{exporter.port}/metrics")
            print(f"   Status: Running")
            
            # Try to fetch metrics
            try:
                import urllib.request
                response = urllib.request.urlopen(f"http://localhost:{exporter.port}/metrics", timeout=2)
                content = response.read().decode('utf-8')
                
                print(f"   Response size: {len(content)} bytes")
                print(f"   Sample output:")
                for line in content.split('\n')[:5]:
                    if line and not line.startswith('#'):
                        print(f"     {line}")
                
                results["http_server"] = True
            except Exception as e:
                print(f"   ‚ö†Ô∏è  HTTP fetch failed (server may not be fully started): {e}")
        else:
            print("‚ÑπÔ∏è  Prometheus exporter disabled (set ZENCUBE_PROM_ENABLED=1 to enable)")
            results["http_server"] = True  # Not an error if disabled
    except Exception as e:
        print(f"‚ùå HTTP server test failed: {e}")
    
    # Test 5: Metric update functionality
    print_section("Test 5: Metric Updates")
    try:
        from monitor.resource_monitor import Sample
        
        test_sample = Sample(
            timestamp=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
            cpu_percent=42.5,
            memory_rss=256 * 1024 * 1024,
            io_read_bytes=1000,
            io_write_bytes=2000,
            open_files=15,
            num_threads=4,
            socket_count=2
        )
        
        # Update metrics
        exporter.update_from_sample("test_run", test_sample)
        
        print("‚úÖ Metrics updated successfully")
        print(f"   Run ID: test_run")
        print(f"   CPU: {test_sample.cpu_percent}%")
        print(f"   Memory: {test_sample.memory_rss / 1024 / 1024:.0f} MB")
        print(f"   I/O Read: {test_sample.io_read_bytes} bytes")
        print(f"   I/O Write: {test_sample.io_write_bytes} bytes")
        
        results["metric_update"] = True
    except Exception as e:
        print(f"‚ùå Metric update failed: {e}")
    
    return results

def print_summary(results_3a, results_3b, results_3c):
    """Print overall test summary"""
    print_header("PHASE-3 TEST SUMMARY")
    
    # Calculate totals
    total_3a = sum(results_3a.values())
    max_3a = len(results_3a)
    total_3b = sum(results_3b.values())
    max_3b = len(results_3b)
    total_3c = sum(results_3c.values())
    max_3c = len(results_3c)
    
    total_all = total_3a + total_3b + total_3c
    max_all = max_3a + max_3b + max_3c
    
    print("\nüìä PHASE-3A: RESOURCE MONITORING & CHARTS")
    print(f"   Tests Passed: {total_3a}/{max_3a}")
    for test, passed in results_3a.items():
        status = "‚úÖ" if passed else "‚ùå"
        print(f"   {status} {test.replace('_', ' ').title()}")
    
    print("\nüìä PHASE-3B: ALERT MANAGEMENT")
    print(f"   Tests Passed: {total_3b}/{max_3b}")
    for test, passed in results_3b.items():
        status = "‚úÖ" if passed else "‚ùå"
        print(f"   {status} {test.replace('_', ' ').title()}")
    
    print("\nüìä PHASE-3C: PROMETHEUS EXPORTER")
    print(f"   Tests Passed: {total_3c}/{max_3c}")
    for test, passed in results_3c.items():
        status = "‚úÖ" if passed else "‚ùå"
        print(f"   {status} {test.replace('_', ' ').title()}")
    
    print("\n" + "=" * 80)
    print(f"  OVERALL RESULTS: {total_all}/{max_all} tests passed")
    
    percentage = (total_all / max_all * 100) if max_all > 0 else 0
    print(f"  Success Rate: {percentage:.1f}%")
    
    if percentage == 100:
        print("\n  üéâ ALL PHASE-3 COMPONENTS WORKING PERFECTLY!")
    elif percentage >= 80:
        print("\n  ‚úÖ PHASE-3 MOSTLY FUNCTIONAL - Minor issues detected")
    elif percentage >= 50:
        print("\n  ‚ö†Ô∏è  PHASE-3 PARTIALLY WORKING - Some components need attention")
    else:
        print("\n  ‚ùå PHASE-3 HAS SIGNIFICANT ISSUES - Debugging required")
    
    print("=" * 80)

def main():
    """Main test execution"""
    print("\n" + "üßä" * 40)
    print("  ZENCUBE PHASE-3 COMPREHENSIVE TEST SUITE")
    print("  Testing: Monitoring, Alerting, and Prometheus Export")
    print("üßä" * 40)
    
    # Run all tests
    results_3a = test_phase3a_monitoring()
    results_3b = test_phase3b_alerting()
    results_3c = test_phase3c_prometheus()
    
    # Print summary
    print_summary(results_3a, results_3b, results_3c)
    
    print("\nüí° TIP: To see real-time monitoring in the GUI:")
    print("   1. Run: python3 zencube/zencube_modern_gui.py")
    print("   2. Check 'Enable monitoring for executions'")
    print("   3. Execute a command like: /bin/sleep 10")
    print("   4. Watch the charts populate with real-time data!\n")

if __name__ == "__main__":
    main()
